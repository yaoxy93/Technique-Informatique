# app.py ‚Äî Dashboard CSV robuste (auto-d√©tection du s√©parateur)
# -------------------------------------------------------------
# Points cl√©s :
# - Auto-d√©tection du s√©parateur via csv.Sniffer() + fallback intelligent
# - G√®re UTF-8/UTF-8-SIG/Latin-1, guillemets, lignes probl√©matiques
# - Nettoyage des colonnes + conversion num√©rique (virgules d√©cimales -> points)
# - S√©lecteur manuel de s√©parateur en secours (sidebar)
# - Mini dashboard (aper√ßu + 3 graphes de base) pour valider les donn√©es

import csv
import io
import re
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

st.set_page_config(page_title="CSV Auto-Sep Dashboard", page_icon="üìä", layout="wide")

# ============= UTILS =============

def _read_try(file_like, **opts):
    """Essaye une lecture avec pandas et retourne (df, err). Reset le pointeur si n√©cessaire."""
    err = None
    # Important avec st.file_uploader: il faut remettre le curseur au d√©but avant chaque tentative
    if hasattr(file_like, "seek"):
        file_like.seek(0)
    try:
        df = pd.read_csv(file_like, **opts)
        return df, None
    except Exception as e:
        err = e
    return pd.DataFrame(), err

def _detect_sep_from_sample(sample: str) -> str:
    """Devine le s√©parateur dans un √©chantillon texte; fallback ';' si doute."""
    try:
        dialect = csv.Sniffer().sniff(sample, delimiters=";,|\t,")
        return dialect.delimiter
    except Exception:
        # Heuristique simple : si beaucoup de ';' -> ';', sinon ','
        counts = {sep: sample.count(sep) for sep in [",", ";", "\t", "|"]}
        # On pr√©f√®re ';' en Europe quand les comptes sont proches
        if counts[";"] >= counts[","]:
            return ";"
        return max(counts, key=counts.get) or ";"

def _read_text(file_like) -> str:
    """Lit un petit sample du fichier (bytes) et renvoie du texte utf-8 propre pour Sniffer."""
    if hasattr(file_like, "read"):
        pos = file_like.tell()
        chunk = file_like.read(4096)
        # reset
        file_like.seek(pos)
        if isinstance(chunk, bytes):
            try:
                return chunk.decode("utf-8", errors="ignore")
            except Exception:
                return chunk.decode("latin-1", errors="ignore")
        return str(chunk)
    else:
        # Chemin sur disque
        with open(file_like, "rb") as f:
            chunk = f.read(4096)
        try:
            return chunk.decode("utf-8", errors="ignore")
        except Exception:
            return chunk.decode("latin-1", errors="ignore")

def _clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoie et d√©duplique proprement les noms de colonnes."""
    cols = []
    seen = {}
    for c in df.columns:
        cc = str(c).strip()
        cc = cc.replace("\n", " ").replace("\r", " ")
        cc = re.sub(r"\s+", " ", cc)
        # d√©duplication si colonnes dupliqu√©es
        base = cc
        k = 1
        while cc in seen:
            k += 1
            cc = f"{base} ({k})"
        seen[cc] = True
        cols.append(cc)
    df.columns = cols
    return df

def _coerce_numeric_with_commas(df: pd.DataFrame) -> pd.DataFrame:
    """Convertit automatiquement en num√©riques les colonnes object avec virgule d√©cimale (ex: '12,5')."""
    out = df.copy()
    for c in out.columns:
        if out[c].dtype == object:
            s = out[c].astype(str).str.strip()
            # ignore les grandes cha√Ænes type GeoJSON/URL
            if s.str.len().median() > 50:
                continue
            s2 = (
                s.str.replace("\u00a0", " ", regex=False)   # NBSP
                 .str.replace(" ", "", regex=False)         # espaces milliers
                 .str.replace(",", ".", regex=False)        # virgule -> point
            )
            try:
                conv = pd.to_numeric(s2, errors="coerce")
                # On garde si au moins 70% deviennent des nombres
                if conv.notna().mean() >= 0.7:
                    out[c] = conv
            except Exception:
                pass
    return out

@st.cache_data(show_spinner=False)
def load_csv_robust(file_like, manual_sep: str | None = None) -> pd.DataFrame:
    """
    Lecture tr√®s robuste d'un CSV (Streamlit uploader ou chemin).
    - Auto-d√©tecte le s√©parateur (ou utilise manual_sep si fourni)
    - Essaie plusieurs encodages et options (quotes, on_bad_lines)
    - Nettoie les colonnes et tente des conversions num√©riques
    """
    sample = _read_text(file_like)
    sep = manual_sep or _detect_sep_from_sample(sample)

    tries = [
        # Essai standard
        dict(sep=sep, engine="python", encoding="utf-8-sig", quotechar='"'),
        # Variante encodage
        dict(sep=sep, engine="python", encoding="utf-8", quotechar='"'),
        dict(sep=sep, engine="python", encoding="latin-1", quotechar='"'),
        # Si des lignes sont malform√©es, on pr√©f√®re ne pas planter
        dict(sep=sep, engine="python", encoding="utf-8-sig", quotechar='"', on_bad_lines="skip"),
    ]

    last_err = None
    for opts in tries:
        df, err = _read_try(file_like, **opts)
        if err is None and not df.empty:
            df = _clean_columns(df)
            df = _coerce_numeric_with_commas(df)
            return df
        last_err = err

    # Dernier recours : retente avec s√©parateurs alternatifs
    for alt in [",", ";", "\t", "|"]:
        if alt == sep:
            continue
        df, err = _read_try(file_like, sep=alt, engine="python", encoding="utf-8-sig", quotechar='"')
        if err is None and not df.empty:
            df = _clean_columns(df)
            df = _coerce_numeric_with_commas(df)
            return df
        last_err = err

    st.error(f"Erreur de lecture du CSV : {last_err}")
    return pd.DataFrame()

# ============= UI =============

st.title("üìä CSV Auto-Sep Dashboard (z√©ro prise de t√™te)")

with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres d‚Äôimport")
    manual_toggle = st.toggle("Forcer un s√©parateur", value=False, help="√Ä cocher si l'auto-d√©tection n'est pas bonne.")
    manual_sep = None
    if manual_toggle:
        manual_sep = st.radio("S√©parateur", options=[";", ",", "\\t", "|"], index=0, horizontal=True)
        if manual_sep == "\\t":
            manual_sep = "\t"
    st.caption("Astuce : les donn√©es europ√©ennes sont souvent en `;`.")

file = st.file_uploader("Charge un fichier CSV", type=["csv"])
if not file:
    st.info("‚û°Ô∏è Uploade un CSV pour commencer.")
    st.stop()

df = load_csv_robust(file, manual_sep=manual_sep)

if df.empty:
    st.warning("Le fichier a √©t√© lu, mais le tableau est vide (ou toutes les lignes ont √©t√© ignor√©es).")
    st.stop()

st.success("‚úÖ CSV charg√© !")
st.write("Aper√ßu :", df.head(50))

# ============= MINI DASHBOARD pour valider =============

num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
cat_cols = [c for c in df.columns if c not in num_cols and df[c].nunique(dropna=True) <= 100]

col1, col2, col3 = st.columns(3)
col1.metric("Lignes", f"{len(df):,}".replace(",", " "))
col2.metric("Colonnes", f"{df.shape[1]}")
col3.metric("Num√©riques", f"{len(num_cols)}")

tabs = st.tabs(["üìä Barres", "üü¢ Nuage de points", "ü•ß Camembert"])

with tabs[0]:
    st.subheader("Barres agr√©g√©es")
    if not num_cols or not cat_cols:
        st.info("Besoin d‚Äôau moins 1 num√©rique + 1 cat√©gorielle.")
    else:
        g = st.selectbox("Grouper par", cat_cols, key="bar_g")
        y = st.selectbox("Mesure", num_cols, key="bar_y")
        how = st.selectbox("Agr√©gation", ["sum", "mean", "median", "min", "max"], index=0, key="bar_how")
        topn = st.slider("Top N", 3, 30, 10, key="bar_topn")
        data = df.groupby(g, dropna=False)[y].agg(how).sort_values(ascending=False).head(topn)
        fig, ax = plt.subplots(figsize=(8,4))
        ax.bar(data.index.astype(str), data.values)
        ax.set_xlabel(g); ax.set_ylabel(y); ax.set_title(f"{how} de {y} par {g}")
        plt.xticks(rotation=30, ha="right")
        st.pyplot(fig)

with tabs[1]:
    st.subheader("Nuage de points")
    if len(num_cols) < 2:
        st.info("Besoin d‚Äôau moins 2 colonnes num√©riques.")
    else:
        x = st.selectbox("X", num_cols, index=0, key="sc_x")
        y = st.selectbox("Y", num_cols, index=1 if len(num_cols)>1 else 0, key="sc_y")
        fig, ax = plt.subplots(figsize=(7,4))
        ax.scatter(df[x], df[y], alpha=0.85)
        ax.set_xlabel(x); ax.set_ylabel(y); ax.set_title(f"{y} vs {x}")
        st.pyplot(fig)

with tabs[2]:
    st.subheader("R√©partition (camembert)")
    if not cat_cols:
        st.info("Besoin d‚Äôune colonne cat√©gorielle.")
    else:
        c = st.selectbox("Cat√©gorie", cat_cols, key="pie_c")
        series = df[c].astype(str).value_counts().head(12)
        fig, ax = plt.subplots(figsize=(6,6))
        ax.pie(series.values, labels=series.index, autopct="%.1f%%", startangle=90)
        ax.set_title(f"R√©partition de {c} (Top 12)")
        st.pyplot(fig)
